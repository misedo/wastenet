{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch & Hugging Face Setup for NVIDIA RTX 50 Series GPUs\n",
    "\n",
    "\n",
    "This notebook demonstrates how to set up and use PyTorch with NVIDIA RTX 5090 GPU,\n",
    "including basic tensor operations and Hugging Face model inference.\n",
    "\n",
    "Requirements:\n",
    "- NVIDIA RTX 50 series GPU\n",
    "- Ubuntu 24.04 LTS\n",
    "- NVIDIA Driver 570.86.16 or later\n",
    "\n",
    "\n",
    "Downloads NVIDIA drivers by going here [https://www.nvidia.com/en-us/drivers/](https://www.nvidia.com/en-us/drivers/) and download .run file\n",
    "\n",
    "\n",
    "### Installing PyTorch, Torchvision, and Torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/nightly/cu128\n",
      "Requirement already satisfied: torch in ./wasteenv/lib/python3.12/site-packages (2.8.0.dev20250622+cu128)\n",
      "Requirement already satisfied: torchvision in ./wasteenv/lib/python3.12/site-packages (0.23.0.dev20250622+cu128)\n",
      "Requirement already satisfied: torchaudio in ./wasteenv/lib/python3.12/site-packages (2.8.0.dev20250622+cu128)\n",
      "Requirement already satisfied: filelock in ./wasteenv/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./wasteenv/lib/python3.12/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: setuptools in ./wasteenv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./wasteenv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./wasteenv/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./wasteenv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./wasteenv/lib/python3.12/site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./wasteenv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./wasteenv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./wasteenv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./wasteenv/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./wasteenv/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./wasteenv/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./wasteenv/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./wasteenv/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./wasteenv/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./wasteenv/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in ./wasteenv/lib/python3.12/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.2.5 in ./wasteenv/lib/python3.12/site-packages (from torch) (3.2.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./wasteenv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./wasteenv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./wasteenv/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: pytorch-triton==3.3.1+gitc8757738 in ./wasteenv/lib/python3.12/site-packages (from torch) (3.3.1+gitc8757738)\n",
      "Requirement already satisfied: numpy in ./wasteenv/lib/python3.12/site-packages (from torchvision) (2.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./wasteenv/lib/python3.12/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./wasteenv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./wasteenv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: soundfile in ./wasteenv/lib/python3.12/site-packages (0.13.1)\n",
      "Requirement already satisfied: cffi>=1.0 in ./wasteenv/lib/python3.12/site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: numpy in ./wasteenv/lib/python3.12/site-packages (from soundfile) (2.3.0)\n",
      "Requirement already satisfied: pycparser in ./wasteenv/lib/python3.12/site-packages (from cffi>=1.0->soundfile) (2.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128\n",
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0.dev20250622+cu128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Test PyTorch installation\n",
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Using GPU.\n",
      "Tensor x:\n",
      " tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "Tensor y (x + 2):\n",
      " tensor([[3., 4.],\n",
      "        [5., 6.]])\n",
      "Matrix multiplication (x @ y):\n",
      " tensor([[13., 16.],\n",
      "        [29., 36.]])\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use GPU\n",
    "    print(\"CUDA is available! Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Use CPU\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Create a tensor\n",
    "x = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "print(\"Tensor x:\\n\", x)\n",
    "\n",
    "# Perform basic operations\n",
    "y = x + 2\n",
    "print(\"Tensor y (x + 2):\\n\", y)\n",
    "\n",
    "z = torch.matmul(x, y)\n",
    "print(\"Matrix multiplication (x @ y):\\n\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torchaudio version: 2.8.0.dev20250622+cu128\n",
      "Torchvision version: 0.23.0.dev20250622+cu128\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import torchvision\n",
    "\n",
    "# Print versions to verify installation\n",
    "print(f\"Torchaudio version: {torchaudio.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Audio shape: torch.Size([1, 40000])\n",
      "Sample rate: 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MNIST Dataset size: 60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic audio loading test\n",
    "file = torchaudio.utils.download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo-8000hz.wav\")\n",
    "waveform, sample_rate = torchaudio.load(file) \n",
    "print(f\"\\nAudio shape: {waveform.shape}\")\n",
    "print(f\"Sample rate: {sample_rate}\")\n",
    "\n",
    "# Basic image loading test\n",
    "from torchvision import datasets\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    download = True\n",
    ")\n",
    "print(f\"\\nMNIST Dataset size: {len(train_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.8.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting huggingface_hub[cli]\n",
      "  Using cached huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: filelock in ./wasteenv/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./wasteenv/lib/python3.12/site-packages (from transformers) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./wasteenv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./wasteenv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in ./wasteenv/lib/python3.12/site-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in ./wasteenv/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./wasteenv/lib/python3.12/site-packages (from accelerate) (2.8.0.dev20250622+cu128)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./wasteenv/lib/python3.12/site-packages (from huggingface_hub[cli]) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./wasteenv/lib/python3.12/site-packages (from huggingface_hub[cli]) (4.14.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface_hub[cli])\n",
      "  Using cached hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Collecting InquirerPy==0.3.4 (from huggingface_hub[cli])\n",
      "  Using cached InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface_hub[cli])\n",
      "  Using cached pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in ./wasteenv/lib/python3.12/site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.51)\n",
      "Requirement already satisfied: setuptools in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.2.5 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.2.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: pytorch-triton==3.3.1+gitc8757738 in ./wasteenv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.3.1+gitc8757738)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./wasteenv/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./wasteenv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./wasteenv/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./wasteenv/lib/python3.12/site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: wcwidth in ./wasteenv/lib/python3.12/site-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.13)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./wasteenv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./wasteenv/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Using cached transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "Using cached accelerate-1.8.1-py3-none-any.whl (365 kB)\n",
      "Using cached InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
      "Using cached hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, pfzy, hf-xet, InquirerPy, huggingface_hub, tokenizers, transformers, accelerate\n",
      "Successfully installed InquirerPy-0.3.4 accelerate-1.8.1 hf-xet-1.1.5 huggingface_hub-0.33.0 pfzy-0.3.4 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.52.4\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate \"huggingface_hub[cli]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and test Hugging Face by running Llama 3.2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74de1fe7f964ce08a6b92943dc2831e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Explain GPU acceleration: GPU stands for graphics processing unit. It is a specialized electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images in a frame buffer intended for output to a display device. These processors are used in embedded systems such as mobile phones, video game consoles, and personal computers. GPUs are very efficient at manipulating computer graphics, and are therefore used for 3D graphics applications such as video games and interactive 3D applications. GPUs are used in other applications such as video encoding, video\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B\", \n",
    "                                             device_map=\"auto\", \n",
    "                                             torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B\")\n",
    "inputs = tokenizer(\"Explain GPU acceleration:\", return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
